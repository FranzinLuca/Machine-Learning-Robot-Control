{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e99e7b",
   "metadata": {},
   "source": [
    "## Main notebook to run and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7321614",
   "metadata": {},
   "source": [
    "### 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from src.config import Config\n",
    "from src.utils import set_seed, plot_loss_curves, plot_results_publication\n",
    "from src.data_loader import load_and_process_data\n",
    "from src.model import DynamicMLP\n",
    "from src.train import train_one_epoch, validate\n",
    "from src.optimization import objective\n",
    "from src.test import evaluate_model\n",
    "from src.data_loader import load_test_data\n",
    "from src.utils import EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from src.utils import save_artifacts\n",
    "\n",
    "# Check device\n",
    "device = Config.DEVICE\n",
    "id_robot = 1 # 0 = 3 joint, 1 = 4 joint, 2 = 6 joint\n",
    "writer = SummaryWriter(f\"runs/{Config.ROBOT_CHOICE[id_robot]}_experiment\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcfd877",
   "metadata": {},
   "source": [
    "### 2. Robot Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be385b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "ROBOT_CHOICE = Config.ROBOT_CHOICE[id_robot]  # Choose the robot configuration here\n",
    "\n",
    "if ROBOT_CHOICE == \"Reacher3\":\n",
    "    # Train file\n",
    "    CSV_PATHS = [os.path.join(Config.DATA_DIR, f\"reacher3_train_{i}.csv\") for i in [1,2]]\n",
    "    # Test file\n",
    "    TEST_CSV_PATHS = [os.path.join(Config.DATA_DIR, f\"reacher3_test_{i}.csv\") for i in [1,2]]\n",
    "    \n",
    "    INPUT_COLS = Config.INPUTS_REACHER3\n",
    "    OUTPUT_COLS = Config.OUTPUTS_REACHER3\n",
    "\n",
    "elif ROBOT_CHOICE == \"Reacher4\":\n",
    "    CSV_PATHS = [os.path.join(Config.DATA_DIR, f\"reacher4_train_{i}.csv\") for i in [1,2]]\n",
    "    TEST_CSV_PATHS = [os.path.join(Config.DATA_DIR, f\"reacher4_test_{i}.csv\") for i in [1,2]]\n",
    "    \n",
    "    INPUT_COLS = Config.INPUTS_REACHER4\n",
    "    OUTPUT_COLS = Config.OUTPUTS_REACHER4\n",
    "\n",
    "elif ROBOT_CHOICE == \"Reacher6\":\n",
    "    CSV_PATHS = [os.path.join(Config.DATA_DIR, f\"reacher6_train_{i}.csv\") for i in [1,2]]\n",
    "    TEST_CSV_PATHS = [os.path.join(Config.DATA_DIR, f\"reacher6_test_{i}.csv\") for i in [1,2]]\n",
    "    \n",
    "    INPUT_COLS = Config.INPUTS_REACHER6\n",
    "    OUTPUT_COLS = Config.OUTPUTS_REACHER6\n",
    "\n",
    "print(f\"Robot: {ROBOT_CHOICE}\")\n",
    "print(f\"Train Files: {CSV_PATHS}\")\n",
    "print(f\"Test Files: {TEST_CSV_PATHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4544c7b",
   "metadata": {},
   "source": [
    "### 3. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b88384",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = Config.SEEDS[2]\n",
    "set_seed(seed) # Reproducibility\n",
    "\n",
    "# Load data\n",
    "train_dataset, val_dataset, x_scaler, y_scaler = load_and_process_data(\n",
    "    CSV_PATHS, INPUT_COLS, OUTPUT_COLS, val_split=0.2\n",
    ")\n",
    "\n",
    "# Create dataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "input_dim = len(INPUT_COLS)\n",
    "output_dim = len(OUTPUT_COLS)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03a202",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter Optimization (Optuna)\n",
    "We search for the best architecture (Layers, Units, LR). Then save the study result of each runn to have a complete overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b96d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if  Config.RUN_OPTIMIZATION:\n",
    "    def run_optuna_study():\n",
    "        study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "        \n",
    "        study.optimize(\n",
    "            lambda trial: objective(trial, train_loader, val_loader, input_dim, output_dim, device), \n",
    "            n_trials=Config.NUM_TRIALS\n",
    "        )\n",
    "        return study\n",
    "\n",
    "    study = run_optuna_study()\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(f\"  Params: {trial.params}\")\n",
    "\n",
    "    # save the study results\n",
    "    study_df = study.trials_dataframe()\n",
    "    study_csv_path = os.path.join(Config.DATA_DIR, f\"optuna_study_{ROBOT_CHOICE}.csv\")\n",
    "    study_df.to_csv(study_csv_path, index=False)\n",
    "else:\n",
    "    print(\"Skipping hyperparameter optimization as per configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a318f3",
   "metadata": {},
   "source": [
    "### 5. Training the Best Model\n",
    "Retrain the model with the best parameters found by Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load params\n",
    "if Config.LOAD_FROM_OPTUNA:\n",
    "    all_study = pd.read_csv(os.path.join(Config.DATA_DIR, f\"optuna_study_{ROBOT_CHOICE}.csv\"))\n",
    "    best_trial_index = all_study['value'].idxmin()\n",
    "    best_row = all_study.iloc[best_trial_index]\n",
    "\n",
    "    # Parse params\n",
    "    n_layers = int(best_row['params_n_layers'])\n",
    "    hidden_layers = [int(best_row[f'params_hidden_units_layer_{i}']) for i in range(n_layers)]\n",
    "    dropout = float(best_row['params_dropout'])\n",
    "    lr = float(best_row['params_lr'])\n",
    "    activation = best_row['params_activation']\n",
    "    raw_res = best_row.get('params_use_residual', False) \n",
    "    use_residual = str(raw_res) == \"True\" or raw_res is True\n",
    "else:\n",
    "    # Get best params from Config\n",
    "    best_params = Config.best_hyperparameters(ROBOT_CHOICE)\n",
    "    n_layers = best_params['num_layers']\n",
    "    hidden_layers = best_params['hidden_units']\n",
    "    dropout = best_params['dropout']\n",
    "    lr = best_params['learning_rate']\n",
    "    activation = best_params['activation']\n",
    "    use_residual = best_params['use_residuals']\n",
    "\n",
    "\n",
    "print(f\"Best Config: Res={use_residual}, Act={activation}, Layers={hidden_layers}\")\n",
    "\n",
    "# Build model\n",
    "model = DynamicMLP(input_dim, output_dim, hidden_layers, dropout, activation=activation, use_residual=use_residual).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "save_path = os.path.join(Config.MODELS_DIR, f\"{ROBOT_CHOICE}_best.pth\")\n",
    "early_stopping = EarlyStopping(patience=15, min_delta=1e-6, path=save_path)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(f\"Starting robust training (Max Epochs: {Config.EPOCHS})...\")\n",
    "\n",
    "for epoch in range(Config.EPOCHS):\n",
    "    t_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, epoch+1, writer)\n",
    "    v_loss, v_r2 = validate(model, val_loader, criterion, device, epoch+1, writer)\n",
    "    \n",
    "    train_losses.append(t_loss)\n",
    "    val_losses.append(v_loss)\n",
    "    \n",
    "    scheduler.step(v_loss)\n",
    "    early_stopping(v_loss, model)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Train: {t_loss:.5f} | Val: {v_loss:.5f} | R2: {v_r2:.4f}\")\n",
    "\n",
    "# Finalize\n",
    "print(\"Loading best model weights...\")\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "# Plot\n",
    "plot_save_path = os.path.join(Config.PLOTS_DIR, f\"{ROBOT_CHOICE}_loss.png\")\n",
    "plot_loss_curves(train_losses, val_losses, save_path=plot_save_path)\n",
    "\n",
    "# Save artifacts\n",
    "save_artifacts(model, x_scaler, y_scaler, \n",
    "               save_dir=Config.MODELS_DIR, \n",
    "               model_name=f\"{ROBOT_CHOICE}_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebac11",
   "metadata": {},
   "source": [
    "### 6. Final Evaluation & Visualization\n",
    "Compute metrics on the validation set in the ORIGINAL scale (Radians)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_dataset = load_test_data(TEST_CSV_PATHS, INPUT_COLS, OUTPUT_COLS, x_scaler, y_scaler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Loaded Test Set: {len(test_dataset)} samples\")\n",
    "\n",
    "# Reconstruct model\n",
    "if Config.LOAD_FROM_OPTUNA:\n",
    "    all_study = pd.read_csv(os.path.join(Config.DATA_DIR, f\"optuna_study_{ROBOT_CHOICE}.csv\"))\n",
    "    best_trial_index = all_study['value'].idxmin()\n",
    "    best_row = all_study.iloc[best_trial_index]\n",
    "\n",
    "    # Parse params\n",
    "    n_layers = int(best_row['params_n_layers'])\n",
    "    hidden_layers = [int(best_row[f'params_hidden_units_layer_{i}']) for i in range(n_layers)]\n",
    "    dropout = float(best_row['params_dropout'])\n",
    "    lr = float(best_row['params_lr'])\n",
    "    activation = best_row['params_activation']\n",
    "    raw_res = best_row.get('params_use_residual', False) \n",
    "    use_residual = str(raw_res) == \"True\" or raw_res is True\n",
    "else:\n",
    "    # Get best params from Config\n",
    "    best_params = Config.best_hyperparameters(ROBOT_CHOICE)\n",
    "    n_layers = best_params['num_layers']\n",
    "    hidden_layers = best_params['hidden_units']\n",
    "    dropout = best_params['dropout']\n",
    "    lr = best_params['learning_rate']\n",
    "    activation = best_params['activation']\n",
    "    use_residual = best_params['use_residuals']\n",
    "\n",
    "model = DynamicMLP(input_dim, output_dim, hidden_layers, dropout, activation=activation, use_residual=use_residual).to(device)\n",
    "# Load Weights\n",
    "weights_path = os.path.join(Config.MODELS_DIR, f\"{ROBOT_CHOICE}_best.pth\")\n",
    "model.load_state_dict(torch.load(weights_path))\n",
    "print(f\"Model loaded from {weights_path}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "metrics, y_true, y_pred = evaluate_model(model, test_loader, y_scaler, device)\n",
    "\n",
    "print(f\"--- Final Test Results ({ROBOT_CHOICE}) ---\")\n",
    "print(f\"R2 Score: {metrics['r2']:.4f}\")\n",
    "print(f\"MSE (Radians^2): {metrics['mse']:.6e}\")\n",
    "\n",
    "# Plots\n",
    "num_joints = output_dim\n",
    "for i in range(num_joints):\n",
    "    plot_results_publication(y_true, y_pred, joint_idx=i, \n",
    "                             robot_name=ROBOT_CHOICE, \n",
    "                             save_dir=Config.PLOTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ffab4",
   "metadata": {},
   "source": [
    "### 7. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf651821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"\n",
    "    Forcefully frees up RAM and VRAM.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "        \n",
    "    print(\"Memory cleaned.\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"GPU Reserved:  {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "vars_to_delete = ['model', 'optimizer', 'scheduler', 'train_loader', 'val_loader', 'test_loader', 'train_dataset', 'val_dataset', 'study']\n",
    "\n",
    "for var in vars_to_delete:\n",
    "    if var in globals():\n",
    "        del globals()[var]\n",
    "\n",
    "cleanup_memory()\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
